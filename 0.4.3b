Collecting crawl4ai
  Downloading Crawl4AI-0.4.248-py3-none-any.whl.metadata (29 kB)
Collecting aiosqlite~=0.20 (from crawl4ai)
  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)
Collecting lxml~=5.3 (from crawl4ai)
  Downloading lxml-5.3.1-cp39-cp39-win_amd64.whl.metadata (3.8 kB)
Collecting litellm>=1.53.1 (from crawl4ai)
  Downloading litellm-1.61.6-py3-none-any.whl.metadata (37 kB)
Collecting numpy<3,>=1.26.0 (from crawl4ai)
  Using cached numpy-2.0.2-cp39-cp39-win_amd64.whl.metadata (59 kB)
Collecting pillow~=10.4 (from crawl4ai)
  Using cached pillow-10.4.0-cp39-cp39-win_amd64.whl.metadata (9.3 kB)
Collecting playwright>=1.49.0 (from crawl4ai)
  Downloading playwright-1.50.0-py3-none-win_amd64.whl.metadata (3.5 kB)
Requirement already satisfied: python-dotenv~=1.0 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from crawl4ai) (1.0.0)
Requirement already satisfied: requests~=2.26 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from crawl4ai) (2.32.3)
Collecting beautifulsoup4~=4.12 (from crawl4ai)
  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)
Collecting tf-playwright-stealth>=1.1.0 (from crawl4ai)
  Downloading tf_playwright_stealth-1.1.1-py3-none-any.whl.metadata (2.6 kB)
Collecting xxhash~=3.4 (from crawl4ai)
  Downloading xxhash-3.5.0-cp39-cp39-win_amd64.whl.metadata (13 kB)
Collecting rank-bm25~=0.2 (from crawl4ai)
  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)
Collecting aiofiles>=24.1.0 (from crawl4ai)
  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)
Requirement already satisfied: colorama~=0.4 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from crawl4ai) (0.4.6)
Collecting snowballstemmer~=2.2 (from crawl4ai)
  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl.metadata (6.5 kB)
Requirement already satisfied: pydantic>=2.10 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from crawl4ai) (2.10.6)
Collecting pyOpenSSL>=24.3.0 (from crawl4ai)
  Downloading pyOpenSSL-25.0.0-py3-none-any.whl.metadata (16 kB)
Collecting psutil>=6.1.1 (from crawl4ai)
  Downloading psutil-7.0.0-cp37-abi3-win_amd64.whl.metadata (23 kB)
Collecting nltk>=3.9.1 (from crawl4ai)
  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)
Collecting rich>=13.9.4 (from crawl4ai)
  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)
Collecting cssselect>=1.2.0 (from crawl4ai)
  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)
Collecting httpx==0.27.2 (from crawl4ai)
  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)
Collecting fake-useragent>=2.0.3 (from crawl4ai)
  Downloading fake_useragent-2.0.3-py3-none-any.whl.metadata (17 kB)
Requirement already satisfied: anyio in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from httpx==0.27.2->crawl4ai) (4.8.0)
Requirement already satisfied: certifi in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from httpx==0.27.2->crawl4ai) (2025.1.31)
Requirement already satisfied: httpcore==1.* in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from httpx==0.27.2->crawl4ai) (1.0.7)
Requirement already satisfied: idna in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from httpx==0.27.2->crawl4ai) (3.10)
Requirement already satisfied: sniffio in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from httpx==0.27.2->crawl4ai) (1.3.1)
Requirement already satisfied: h11<0.15,>=0.13 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from httpcore==1.*->httpx==0.27.2->crawl4ai) (0.14.0)
Requirement already satisfied: typing_extensions>=4.0 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from aiosqlite~=0.20->crawl4ai) (4.12.2)
Collecting soupsieve>1.2 (from beautifulsoup4~=4.12->crawl4ai)
  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)
Collecting importlib-resources>=6.0 (from fake-useragent>=2.0.3->crawl4ai)
  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)
Collecting aiohttp (from litellm>=1.53.1->crawl4ai)
  Downloading aiohttp-3.11.12-cp39-cp39-win_amd64.whl.metadata (8.0 kB)
Requirement already satisfied: click in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from litellm>=1.53.1->crawl4ai) (8.1.8)
Requirement already satisfied: importlib-metadata>=6.8.0 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from litellm>=1.53.1->crawl4ai) (8.6.1)
Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from litellm>=1.53.1->crawl4ai) (3.1.5)
Collecting jsonschema<5.0.0,>=4.22.0 (from litellm>=1.53.1->crawl4ai)
  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)
Requirement already satisfied: openai>=1.61.0 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from litellm>=1.53.1->crawl4ai) (1.63.0)
Collecting tiktoken>=0.7.0 (from litellm>=1.53.1->crawl4ai)
  Downloading tiktoken-0.9.0-cp39-cp39-win_amd64.whl.metadata (6.8 kB)
Collecting tokenizers (from litellm>=1.53.1->crawl4ai)
  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)
Collecting joblib (from nltk>=3.9.1->crawl4ai)
  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)
Collecting regex>=2021.8.3 (from nltk>=3.9.1->crawl4ai)
  Downloading regex-2024.11.6-cp39-cp39-win_amd64.whl.metadata (41 kB)
Requirement already satisfied: tqdm in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from nltk>=3.9.1->crawl4ai) (4.67.1)
Collecting pyee<13,>=12 (from playwright>=1.49.0->crawl4ai)
  Downloading pyee-12.1.1-py3-none-any.whl.metadata (2.9 kB)
Collecting greenlet<4.0.0,>=3.1.1 (from playwright>=1.49.0->crawl4ai)
  Downloading greenlet-3.1.1-cp39-cp39-win_amd64.whl.metadata (3.9 kB)
Requirement already satisfied: annotated-types>=0.6.0 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from pydantic>=2.10->crawl4ai) (0.7.0)
Requirement already satisfied: pydantic-core==2.27.2 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from pydantic>=2.10->crawl4ai) (2.27.2)
Requirement already satisfied: cryptography<45,>=41.0.5 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from pyOpenSSL>=24.3.0->crawl4ai) (44.0.1)
Requirement already satisfied: charset-normalizer<4,>=2 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from requests~=2.26->crawl4ai) (3.4.1)
Requirement already satisfied: urllib3<3,>=1.21.1 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from requests~=2.26->crawl4ai) (2.3.0)
Collecting markdown-it-py>=2.2.0 (from rich>=13.9.4->crawl4ai)
  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)
Collecting pygments<3.0.0,>=2.13.0 (from rich>=13.9.4->crawl4ai)
  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)
Collecting fake-http-header<0.4.0,>=0.3.5 (from tf-playwright-stealth>=1.1.0->crawl4ai)
  Downloading fake_http_header-0.3.5-py3-none-any.whl.metadata (3.5 kB)
Requirement already satisfied: cffi>=1.12 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (1.17.1)
Requirement already satisfied: zipp>=3.20 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from importlib-metadata>=6.8.0->litellm>=1.53.1->crawl4ai) (3.21.0)
Requirement already satisfied: MarkupSafe>=2.0 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.53.1->crawl4ai) (3.0.2)
Collecting attrs>=22.2.0 (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai)
  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)
Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai)
  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)
Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai)
  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)
Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai)
  Downloading rpds_py-0.22.3-cp39-cp39-win_amd64.whl.metadata (4.2 kB)
Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.9.4->crawl4ai)
  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)
Requirement already satisfied: distro<2,>=1.7.0 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from openai>=1.61.0->litellm>=1.53.1->crawl4ai) (1.9.0)
Requirement already satisfied: jiter<1,>=0.4.0 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from openai>=1.61.0->litellm>=1.53.1->crawl4ai) (0.8.2)
Requirement already satisfied: exceptiongroup>=1.0.2 in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from anyio->httpx==0.27.2->crawl4ai) (1.2.2)
Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->litellm>=1.53.1->crawl4ai)
  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)
Collecting aiosignal>=1.1.2 (from aiohttp->litellm>=1.53.1->crawl4ai)
  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)
Collecting async-timeout<6.0,>=4.0 (from aiohttp->litellm>=1.53.1->crawl4ai)
  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)
Collecting frozenlist>=1.1.1 (from aiohttp->litellm>=1.53.1->crawl4ai)
  Downloading frozenlist-1.5.0-cp39-cp39-win_amd64.whl.metadata (14 kB)
Collecting multidict<7.0,>=4.5 (from aiohttp->litellm>=1.53.1->crawl4ai)
  Downloading multidict-6.1.0-cp39-cp39-win_amd64.whl.metadata (5.1 kB)
Collecting propcache>=0.2.0 (from aiohttp->litellm>=1.53.1->crawl4ai)
  Downloading propcache-0.2.1-cp39-cp39-win_amd64.whl.metadata (9.5 kB)
Collecting yarl<2.0,>=1.17.0 (from aiohttp->litellm>=1.53.1->crawl4ai)
  Downloading yarl-1.18.3-cp39-cp39-win_amd64.whl.metadata (71 kB)
Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers->litellm>=1.53.1->crawl4ai)
  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)
Requirement already satisfied: pycparser in c:\users\kyriakos\anaconda3\envs\tweet-scheduler\lib\site-packages (from cffi>=1.12->cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (2.22)
Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai)
  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)
Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai)
  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)
Collecting packaging>=20.9 (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai)
  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)
Collecting pyyaml>=5.1 (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai)
  Downloading PyYAML-6.0.2-cp39-cp39-win_amd64.whl.metadata (2.1 kB)
Downloading Crawl4AI-0.4.248-py3-none-any.whl (182 kB)
Downloading httpx-0.27.2-py3-none-any.whl (76 kB)
Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)
Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)
Downloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)
Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)
Downloading fake_useragent-2.0.3-py3-none-any.whl (201 kB)
Downloading litellm-1.61.6-py3-none-any.whl (6.8 MB)
   ---------------------------------------- 6.8/6.8 MB 2.6 MB/s eta 0:00:00
Downloading lxml-5.3.1-cp39-cp39-win_amd64.whl (3.8 MB)
   ---------------------------------------- 3.8/3.8 MB 2.1 MB/s eta 0:00:00
Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)
   ---------------------------------------- 1.5/1.5 MB 1.9 MB/s eta 0:00:00
Using cached numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)
Using cached pillow-10.4.0-cp39-cp39-win_amd64.whl (2.6 MB)
Downloading playwright-1.50.0-py3-none-win_amd64.whl (34.8 MB)
